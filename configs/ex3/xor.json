{
    "layer_sizes": [2, 2, 2, 1],
    "activations": ["", "tanh", "tanh", "sigmoid"],
    "loss": "bce",
    "optimizer": "adam",
    "optim_kwargs": {
      "learning_rate": 0.1
    },
    "batch_size": 4,
    "max_epochs": 1000
  }